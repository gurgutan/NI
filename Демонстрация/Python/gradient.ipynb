{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более подробный пример смотри в https://colab.research.google.com/github/csc413-uoft/2021/blob/master/assets/tutorials/tut02_pytorch.ipynb#scrollTo=2xOx3qye69jn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели методом градиентного спуска\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаем библиотеку, содержащую функции для автоматического вычисления градиента\n",
    "import autograd.numpy as np\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция сигмоиды\n",
    "def sigmoid(z):\n",
    "    z = 1/(1+np.exp(-z))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, вычисляющая выход простого слоя стандартных нейронов\n",
    "def dense_layer(x, W):\n",
    "    y = sigmoid(np.dot(x,W))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, Error, Cost\n",
    "# Функция  потерь (ошибки модели) на истинных значениях y_true\n",
    "def mse(x, W, y_true): # mean absolute error\n",
    "    y = dense_layer(x, W)\n",
    "    y1 = dense_layer(y, W)\n",
    "    # error = np.sum(np.abs(y_true-y1))\n",
    "    error = np.sum(np.square(y_true-y1))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1=[0.16798161 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "# Вход сети x0\n",
    "x0 = np.array([1., 1.])\n",
    "# Матрица весов первого слоя\n",
    "W1 = np.array([\n",
    "    [-2., 2.],\n",
    "    [0.4, -0.9]\n",
    "])\n",
    "# выход первого слоя\n",
    "y1 = dense_layer(x0, W1)\n",
    "print(f\"y1={y1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error=0.43208904098296796\n",
      "gradient=\n",
      "[[ 0.08487571 -0.01919841]\n",
      " [-0.06325601  0.09849232]]\n"
     ]
    }
   ],
   "source": [
    "# определяем функцию для вычисления градиента от функции mse\n",
    "# первый параметр - функция ошибки mse, второй аргумент - номер парараметра mse, по которому считается градиент\n",
    "mse_grad = grad(mse, 1)\n",
    "# задаем истинные (желаемые) значения выхода\n",
    "y_true = np.array([1.0, 0.0])\n",
    "# вычисляем ошибку модели на истинных значениях\n",
    "e = mse(x0, W1, y_true)\n",
    "print(f\"error={e}\")\n",
    "grad_value = mse_grad(x0, W1, y_true)\n",
    "print(f\"gradient=\\n{grad_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error=0.4117398796685692\n"
     ]
    }
   ],
   "source": [
    "# Уменьшаем значения весов связей на значение градиента\n",
    "pairs_count = 32\n",
    "x = np.array([\n",
    "    [1., 1.],\n",
    "    [0., 1.],\n",
    "    [0.5, 0.],\n",
    "    [0., 0.],\n",
    "])\n",
    "y_true = np.array(\n",
    "    [1.0],\n",
    "    [0.0],\n",
    "    [0.0],\n",
    "    [0.0]\n",
    ")\n",
    "# (x[i], y_true[i])\n",
    "e = 0\n",
    "for i in range(pairs_count):\n",
    "    e += mse(x[i], W1, y_true[i])\n",
    "e /= pairs_count    \n",
    "W1 = W1 - grad_value\n",
    "# e = mse(x0, W1, y_true)\n",
    "print(f\"error={e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=0, y=[0.99999386 0.98201379], error=1.8720128308662338\n",
      "n=1, y=[0.99999405 0.9817841 ], error=1.8686479260568558\n",
      "n=2, y=[0.99999425 0.9815525 ], error=1.8651033145085103\n",
      "n=3, y=[0.99999445 0.98131934], error=1.8613646106753716\n",
      "n=4, y=[0.99999464 0.981085  ], error=1.8574159200895703\n",
      "n=5, y=[0.99999483 0.98084997], error=1.853239648774896\n",
      "n=6, y=[0.99999502 0.98061478], error=1.8488162856839332\n",
      "n=7, y=[0.99999521 0.98038004], error=1.8441241542618754\n",
      "n=8, y=[0.9999954  0.98014647], error=1.8391391287876213\n",
      "n=9, y=[0.99999559 0.97991487], error=1.8338343107121453\n",
      "n=10, y=[0.99999578 0.97968616], error=1.8281796598580864\n",
      "n=11, y=[0.99999596 0.97946139], error=1.822141575147458\n",
      "n=12, y=[0.99999614 0.97924173], error=1.8156824196189945\n",
      "n=13, y=[0.99999632 0.97902849], error=1.808759985086807\n",
      "n=14, y=[0.9999965  0.97882317], error=1.8013268931859043\n",
      "n=15, y=[0.99999668 0.97862739], error=1.793329932206853\n",
      "n=16, y=[0.99999685 0.97844298], error=1.784709333714841\n",
      "n=17, y=[0.99999702 0.97827194], error=1.7753980004497831\n",
      "n=18, y=[0.99999719 0.97811645], error=1.7653207087900689\n",
      "n=19, y=[0.99999736 0.97797889], error=1.7543933270331205\n",
      "n=20, y=[0.99999752 0.97786178], error=1.742522117436752\n",
      "n=21, y=[0.99999768 0.97776779], error=1.7296032285926368\n",
      "n=22, y=[0.99999784 0.9776997 ], error=1.7155225390244229\n",
      "n=23, y=[0.99999799 0.97766033], error=1.700156086661813\n",
      "n=24, y=[0.99999813 0.97765245], error=1.6833714144020675\n",
      "n=25, y=[0.99999828 0.9776787 ], error=1.66503027751639\n",
      "n=26, y=[0.99999842 0.97774138], error=1.6449932831419003\n",
      "n=27, y=[0.99999855 0.97784237], error=1.6231271371786529\n",
      "n=28, y=[0.99999867 0.9779828 ], error=1.5993152030616649\n",
      "n=29, y=[0.99999879 0.9781629 ], error=1.5734719346964114\n",
      "n=30, y=[0.99999891 0.97838169], error=1.5455612966269217\n",
      "n=31, y=[0.99999901 0.97863678], error=1.5156183785406308\n",
      "n=32, y=[0.99999911 0.97892415], error=1.4837719649523535\n",
      "n=33, y=[0.99999921 0.97923808], error=1.450263967379679\n",
      "n=34, y=[0.99999929 0.97957123], error=1.4154598986641131\n",
      "n=35, y=[0.99999937 0.97991488], error=1.3798439706578143\n",
      "n=36, y=[0.99999943 0.9802594 ], error=1.3439941122099757\n",
      "n=37, y=[0.99999949 0.98059484], error=1.3085368110510767\n",
      "n=38, y=[0.99999955 0.98091163], error=1.2740881923235015\n",
      "n=39, y=[0.99999959 0.98120118], error=1.2411934037975518\n",
      "n=40, y=[0.99999964 0.98145639], error=1.2102780011232415\n",
      "n=41, y=[0.99999967 0.98167183], error=1.1816212939601922\n",
      "n=42, y=[0.9999997 0.9818438], error=1.1553543114260434\n",
      "n=43, y=[0.99999973 0.98197007], error=1.131477883938275\n",
      "n=44, y=[0.99999975 0.98204958], error=1.1098923501218525\n",
      "n=45, y=[0.99999977 0.98208212], error=1.0904302645156545\n",
      "n=46, y=[0.99999979 0.98206797], error=1.0728858902891067\n",
      "n=47, y=[0.9999998  0.98200759], error=1.0570383513138346\n",
      "n=48, y=[0.99999982 0.98190147], error=1.042667811540237\n",
      "n=49, y=[0.99999983 0.98174987], error=1.0295655174397005\n",
      "n=50, y=[0.99999984 0.98155278], error=1.017539116934808\n",
      "n=51, y=[0.99999985 0.98130979], error=1.0064146863621788\n",
      "n=52, y=[0.99999985 0.98102004], error=0.9960366544830905\n",
      "n=53, y=[0.99999986 0.98068218], error=0.9862665022902395\n",
      "n=54, y=[0.99999987 0.98029426], error=0.9769808355575463\n",
      "n=55, y=[0.99999987 0.97985378], error=0.9680692072975138\n",
      "n=56, y=[0.99999988 0.97935753], error=0.9594319109190416\n",
      "n=57, y=[0.99999988 0.97880158], error=0.9509778606838424\n",
      "n=58, y=[0.99999989 0.97818116], error=0.9426226103172302\n",
      "n=59, y=[0.99999989 0.97749057], error=0.9342865213597104\n",
      "n=60, y=[0.9999999  0.97672304], error=0.925893070996877\n",
      "n=61, y=[0.9999999  0.97587056], error=0.9173672784219747\n",
      "n=62, y=[0.9999999  0.97492372], error=0.9086342252724645\n",
      "n=63, y=[0.99999991 0.97387141], error=0.8996176470508043\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([2.0, -4.0])\n",
    "W1 = np.array([[4.0, -2.0], [-1.0, -2.0]])\n",
    "y_true = np.array([0.0, 1.0])\n",
    "# коэффициент шага обучения\n",
    "k = 0.2\n",
    "for i in range(64):\n",
    "    y = dense_layer(x0, W1)\n",
    "    e = mse(x0, W1, y_true)\n",
    "    grad_value = mse_grad(x0, W1, y_true)\n",
    "    W1 = W1 - k * grad_value\n",
    "    print(f\"n={i}, y={y}, error={e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=0, y=[0.99999386 0.98201379], error=1.8720128308662338\n",
      "n=1, y=[0.99999424 0.98155153], error=1.8651951470438979\n",
      "n=2, y=[0.99999485 0.98076658], error=1.8530053373239983\n",
      "n=3, y=[0.99999569 0.97949076], error=1.8314128354920884\n",
      "n=4, y=[0.99999683 0.97731208], error=1.7892229139355897\n",
      "n=5, y=[0.99999827 0.97296852], error=1.6853503063096649\n",
      "n=6, y=[0.99999965 0.96063227], error=1.313058409889357\n",
      "n=7, y=[1.         0.90923445], error=0.7019131499534418\n",
      "n=8, y=[1.         0.98709431], error=0.959890225239693\n",
      "n=9, y=[1.        0.9873777], error=0.9618260408136913\n",
      "n=10, y=[1.         0.98738901], error=0.9625939045295726\n",
      "n=11, y=[1.         0.98716436], error=0.9623867829596695\n",
      "n=12, y=[1.         0.98668846], error=0.9612162059671916\n",
      "n=13, y=[1.         0.98589293], error=0.9589322975922829\n",
      "n=14, y=[1.         0.98462473], error=0.9551587440494931\n",
      "n=15, y=[1.         0.98255138], error=0.9490795470071106\n",
      "n=16, y=[1.         0.97886116], error=0.9387911722297756\n",
      "n=17, y=[1.         0.97103871], error=0.9188874369706159\n",
      "n=18, y=[1.         0.94679669], error=0.8670627777640111\n",
      "n=19, y=[1.         0.73797322], error=0.610633270185765\n",
      "n=20, y=[1.        0.6835143], error=0.11799836476111311\n",
      "n=21, y=[0.99999999 0.42987562], error=0.34072692379023356\n",
      "n=22, y=[9.99998160e-01 7.57496105e-25], error=1.3650445100872923\n",
      "n=23, y=[9.99999999e-01 7.57092207e-25], error=1.9724936899400949\n",
      "n=24, y=[9.99999999e-01 7.57062273e-25], error=1.9732359113072138\n",
      "n=25, y=[9.99999999e-01 7.57040789e-25], error=1.973787068777217\n",
      "n=26, y=[9.99999999e-01 7.57027397e-25], error=1.974176148046133\n",
      "n=27, y=[9.99999999e-01 7.57021857e-25], error=1.9744220678749282\n",
      "n=28, y=[9.99999999e-01 7.57024025e-25], error=1.9745364212033838\n",
      "n=29, y=[9.99999999e-01 7.57033841e-25], error=1.9745250123047515\n",
      "n=30, y=[9.99999999e-01 7.57051319e-25], error=1.97438861482782\n",
      "n=31, y=[9.99999999e-01 7.57076546e-25], error=1.9741231464063058\n",
      "n=32, y=[9.99999999e-01 7.57109689e-25], error=1.9737193137364477\n",
      "n=33, y=[9.99999999e-01 7.57151000e-25], error=1.9731616656490325\n",
      "n=34, y=[9.99999999e-01 7.57200833e-25], error=1.9724268566359329\n",
      "n=35, y=[9.99999999e-01 7.57259668e-25], error=1.971480716871202\n",
      "n=36, y=[9.99999999e-01 7.57328147e-25], error=1.9702733537211325\n",
      "n=37, y=[9.99999999e-01 7.57407132e-25], error=1.968730773757558\n",
      "n=38, y=[9.99999999e-01 7.57497798e-25], error=1.9667399346009602\n",
      "n=39, y=[9.99999999e-01 7.57601774e-25], error=1.9641204578483333\n",
      "n=40, y=[9.99999998e-01 7.57721407e-25], error=1.9605668142654733\n",
      "n=41, y=[9.99999998e-01 7.57860233e-25], error=1.9555176301709039\n",
      "n=42, y=[9.99999997e-01 7.58023942e-25], error=1.947817394548645\n",
      "n=43, y=[9.99999995e-01 7.58222579e-25], error=1.9346563762013305\n",
      "n=44, y=[9.99999989e-01 7.58476512e-25], error=1.907125969829294\n",
      "n=45, y=[9.99999953e-01 7.58837299e-25], error=1.8195512322499237\n",
      "n=46, y=[9.99994011e-01 7.59494646e-25], error=1.2100602592189782\n",
      "n=47, y=[8.19090369e-01 7.60467662e-25], error=0.9999401469252748\n",
      "n=48, y=[8.1899073e-01 7.6051775e-25], error=0.9999400407092968\n",
      "n=49, y=[8.18811729e-01 7.60616562e-25], error=0.9999398501203144\n",
      "n=50, y=[8.18552187e-01 7.60764517e-25], error=0.9999395733758177\n",
      "n=51, y=[8.18210277e-01 7.60962282e-25], error=0.9999392077522044\n",
      "n=52, y=[8.17783487e-01 7.61210784e-25], error=0.9999387495039552\n",
      "n=53, y=[8.17268547e-01 7.61511240e-25], error=0.9999381937474904\n",
      "n=54, y=[8.16661351e-01 7.61865172e-25], error=0.9999375343023261\n",
      "n=55, y=[8.15956835e-01 7.62274458e-25], error=0.9999367634788499\n",
      "n=56, y=[8.15148831e-01 7.62741368e-25], error=0.9999358717975018\n",
      "n=57, y=[8.14229869e-01 7.63268634e-25], error=0.9999348476177108\n",
      "n=58, y=[8.13190924e-01 7.63859528e-25], error=0.9999336766455813\n",
      "n=59, y=[8.12021082e-01 7.64517965e-25], error=0.999932341275389\n",
      "n=60, y=[8.10707098e-01 7.65248642e-25], error=0.9999308196987234\n",
      "n=61, y=[8.09232805e-01 7.66057210e-25], error=0.9999290846820218\n",
      "n=62, y=[8.07578317e-01 7.66950523e-25], error=0.9999271018602728\n",
      "n=63, y=[8.05718916e-01 7.67936957e-25], error=0.9999248273075536\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([2.0, -4.0])\n",
    "W1 = np.array([[4.0, -2.0], [-1.0, -2.0]])\n",
    "y_true = np.array([0.0, 1.0])\n",
    "# коэффициент шага обучения\n",
    "k = 0.2\n",
    "y = dense_layer(x0, W1)\n",
    "e = mse(x0, W1, y_true)\n",
    "grad_value = mse_grad(x0, W1, y_true)\n",
    "grad_prev = grad_value\n",
    "p_prev = grad_value\n",
    "for i in range(64):\n",
    "    y = dense_layer(x0, W1)\n",
    "    e = mse(x0, W1, y_true)\n",
    "    grad_value = mse_grad(x0, W1, y_true)\n",
    "    beta = np.dot(grad_value, grad_value) / np.dot(grad_prev, grad_prev)\n",
    "    p = grad_value + beta * p_prev\n",
    "    W1 = W1 - k * p\n",
    "    grad_prev = grad_value\n",
    "    p_prev = p\n",
    "    print(f\"n={i}, y={y}, error={e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=[0.99999386 0.98201379], error=1.8720128308662338\n",
      "y=[0.99999424 0.98155153], error=1.8651951470438979\n",
      "y=[0.99999485 0.98076658], error=1.8530053373239983\n",
      "y=[0.99999569 0.97949076], error=1.8314128354920884\n",
      "y=[0.99999683 0.97731208], error=1.7892229139355897\n",
      "y=[0.99999827 0.97296852], error=1.6853503063096649\n",
      "y=[0.99999965 0.96063227], error=1.313058409889357\n",
      "y=[1.         0.90923445], error=0.7019131499534418\n",
      "y=[1.         0.98709431], error=0.959890225239693\n",
      "y=[1.        0.9873777], error=0.9618260408136913\n",
      "y=[1.         0.98738901], error=0.9625939045295726\n",
      "y=[1.         0.98716436], error=0.9623867829596695\n",
      "y=[1.         0.98668846], error=0.9612162059671916\n",
      "y=[1.         0.98589293], error=0.9589322975922829\n",
      "y=[1.         0.98462473], error=0.9551587440494931\n",
      "y=[1.         0.98255138], error=0.9490795470071106\n",
      "y=[1.         0.97886116], error=0.9387911722297756\n",
      "y=[1.         0.97103871], error=0.9188874369706159\n",
      "y=[1.         0.94679669], error=0.8670627777640111\n",
      "y=[1.         0.73797322], error=0.610633270185765\n",
      "y=[1.        0.6835143], error=0.11799836476111311\n",
      "y=[0.99999999 0.42987562], error=0.34072692379023356\n",
      "y=[9.99998160e-01 7.57496105e-25], error=1.3650445100872923\n",
      "y=[9.99999999e-01 7.57092207e-25], error=1.9724936899400949\n",
      "y=[9.99999999e-01 7.57062273e-25], error=1.9732359113072138\n",
      "y=[9.99999999e-01 7.57040789e-25], error=1.973787068777217\n",
      "y=[9.99999999e-01 7.57027397e-25], error=1.974176148046133\n",
      "y=[9.99999999e-01 7.57021857e-25], error=1.9744220678749282\n",
      "y=[9.99999999e-01 7.57024025e-25], error=1.9745364212033838\n",
      "y=[9.99999999e-01 7.57033841e-25], error=1.9745250123047515\n",
      "y=[9.99999999e-01 7.57051319e-25], error=1.97438861482782\n",
      "y=[9.99999999e-01 7.57076546e-25], error=1.9741231464063058\n",
      "y=[9.99999999e-01 7.57109689e-25], error=1.9737193137364477\n",
      "y=[9.99999999e-01 7.57151000e-25], error=1.9731616656490325\n",
      "y=[9.99999999e-01 7.57200833e-25], error=1.9724268566359329\n",
      "y=[9.99999999e-01 7.57259668e-25], error=1.971480716871202\n",
      "y=[9.99999999e-01 7.57328147e-25], error=1.9702733537211325\n",
      "y=[9.99999999e-01 7.57407132e-25], error=1.968730773757558\n",
      "y=[9.99999999e-01 7.57497798e-25], error=1.9667399346009602\n",
      "y=[9.99999999e-01 7.57601774e-25], error=1.9641204578483333\n",
      "y=[9.99999998e-01 7.57721407e-25], error=1.9605668142654733\n",
      "y=[9.99999998e-01 7.57860233e-25], error=1.9555176301709039\n",
      "y=[9.99999997e-01 7.58023942e-25], error=1.947817394548645\n",
      "y=[9.99999995e-01 7.58222579e-25], error=1.9346563762013305\n",
      "y=[9.99999989e-01 7.58476512e-25], error=1.907125969829294\n",
      "y=[9.99999953e-01 7.58837299e-25], error=1.8195512322499237\n",
      "y=[9.99994011e-01 7.59494646e-25], error=1.2100602592189782\n",
      "y=[8.19090369e-01 7.60467662e-25], error=0.9999401469252748\n",
      "y=[8.1899073e-01 7.6051775e-25], error=0.9999400407092968\n",
      "y=[8.18811729e-01 7.60616562e-25], error=0.9999398501203144\n",
      "y=[8.18552187e-01 7.60764517e-25], error=0.9999395733758177\n",
      "y=[8.18210277e-01 7.60962282e-25], error=0.9999392077522044\n",
      "y=[8.17783487e-01 7.61210784e-25], error=0.9999387495039552\n",
      "y=[8.17268547e-01 7.61511240e-25], error=0.9999381937474904\n",
      "y=[8.16661351e-01 7.61865172e-25], error=0.9999375343023261\n",
      "y=[8.15956835e-01 7.62274458e-25], error=0.9999367634788499\n",
      "y=[8.15148831e-01 7.62741368e-25], error=0.9999358717975018\n",
      "y=[8.14229869e-01 7.63268634e-25], error=0.9999348476177108\n",
      "y=[8.13190924e-01 7.63859528e-25], error=0.9999336766455813\n",
      "y=[8.12021082e-01 7.64517965e-25], error=0.999932341275389\n",
      "y=[8.10707098e-01 7.65248642e-25], error=0.9999308196987234\n",
      "y=[8.09232805e-01 7.66057210e-25], error=0.9999290846820218\n",
      "y=[8.07578317e-01 7.66950523e-25], error=0.9999271018602728\n",
      "y=[8.05718916e-01 7.67936957e-25], error=0.9999248273075536\n"
     ]
    }
   ],
   "source": [
    "# Все тоже самое, но делаем 8 итераций обучения\n",
    "x0 = np.array([2.0, -4.0])\n",
    "W1 = np.array([[4.0, -2.0], [-1.0, -2.0]])\n",
    "y_true = np.array([0.0, 1.0])\n",
    "# коэффициент шага обучения\n",
    "k = 0.2\n",
    "y = dense_layer(x0, W1)\n",
    "e = mse(x0, W1, y_true)\n",
    "grad_value = mse_grad(x0, W1, y_true)\n",
    "grad_prev = grad_value\n",
    "p_prev = grad_value\n",
    "for i in range(64):\n",
    "    y = dense_layer(x0, W1)\n",
    "    e = mse(x0, W1, y_true)\n",
    "    grad_value = mse_grad(x0, W1, y_true)\n",
    "    beta = np.dot(grad_value, grad_value) / np.dot(grad_prev, grad_prev)\n",
    "    p = grad_value + beta * p_prev\n",
    "    W1 = W1 - k * p\n",
    "    grad_prev = grad_value\n",
    "    p_prev = p\n",
    "    print(f\"y={y}, error={e}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae7f53e8dd80b02e0612f72962c8cfdaf11ca92c079bdaddd1482a56edc14533"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
